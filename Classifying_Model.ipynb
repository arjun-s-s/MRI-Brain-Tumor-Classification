{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4672 images belonging to 4 classes.\n",
      "Found 576 images belonging to 4 classes.\n",
      "Found 576 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arjun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1), kernel_regularizer=L2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=L2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=L2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=L2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "base_dir = 'brain_tumor_mris'\n",
    "sub_dirs = ['Testing', 'Training', 'Validation']\n",
    "categories = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Initialize variables to store minimum width and height\n",
    "min_width = float('inf')\n",
    "min_height = float('inf')\n",
    "\n",
    "# Iterate through all images to find the minimum width and height\n",
    "for sub_dir in sub_dirs:\n",
    "    for category in categories:\n",
    "        path = os.path.join(base_dir, sub_dir, category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                image = io.imread(img_path, as_gray=True)\n",
    "                height, width = image.shape\n",
    "                if width < min_width:\n",
    "                    min_width = width\n",
    "                if height < min_height:\n",
    "                    min_height = height\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img}: {e}\")\n",
    "\n",
    "print(f\"Minimum width: {min_width}\")\n",
    "print(f\"Minimum height: {min_height}\")\n",
    "\n",
    "#min width 150\n",
    "#max height 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "base_dir = 'brain_tumor_mris'\n",
    "output_dir = 'resized_brain_tumor_mris'\n",
    "sub_dirs = ['Testing', 'Training', 'Validation']\n",
    "categories = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "for sub_dir in sub_dirs:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_dir, sub_dir, category), exist_ok=True)\n",
    "\n",
    "# Function to resize images\n",
    "def resize_image(image_path, size=(150, 150)):\n",
    "    with Image.open(image_path) as img:\n",
    "        # Convert image to RGB if it's in a different mode\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        resized_img = img.resize(size)\n",
    "        return resized_img\n",
    "\n",
    "# Iterate through all images and resize them\n",
    "for sub_dir in sub_dirs:\n",
    "    for category in categories:\n",
    "        input_path = os.path.join(base_dir, sub_dir, category)\n",
    "        output_path = os.path.join(output_dir, sub_dir, category)\n",
    "        for img in os.listdir(input_path):\n",
    "            try:\n",
    "                img_path = os.path.join(input_path, img)\n",
    "                resized_img = resize_image(img_path)\n",
    "                resized_img.save(os.path.join(output_path, img))  # Save resized image as a copy\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img}: {e}\")\n",
    "\n",
    "print(\"All images have been resized to 150x150 pixels and saved as copies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "train_dir = 'resized_brain_tumor_mris/Training'\n",
    "val_dir = 'resized_brain_tumor_mris/Validation'\n",
    "test_dir = 'resized_brain_tumor_mris/Testing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4672 images belonging to 4 classes.\n",
      "Found 576 images belonging to 4 classes.\n",
      "Found 576 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 1), kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (2, 2), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (2, 2), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['f1_score'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 274ms/step - f1_score: 0.5247 - loss: 1.8260 - val_f1_score: 0.1135 - val_loss: 14.9467\n",
      "Epoch 2/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 308ms/step - f1_score: 0.6632 - loss: 1.4079 - val_f1_score: 0.1000 - val_loss: 37.0714\n",
      "Epoch 3/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 289ms/step - f1_score: 0.6876 - loss: 1.3002 - val_f1_score: 0.1184 - val_loss: 7.8516\n",
      "Epoch 4/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 291ms/step - f1_score: 0.6922 - loss: 1.2738 - val_f1_score: 0.4005 - val_loss: 1.9589\n",
      "Epoch 5/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 300ms/step - f1_score: 0.7066 - loss: 1.1954 - val_f1_score: 0.4855 - val_loss: 1.5811\n",
      "Epoch 6/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 291ms/step - f1_score: 0.7342 - loss: 1.1268 - val_f1_score: 0.4975 - val_loss: 1.9238\n",
      "Epoch 7/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 287ms/step - f1_score: 0.7535 - loss: 1.0628 - val_f1_score: 0.3198 - val_loss: 2.9428\n",
      "Epoch 8/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 285ms/step - f1_score: 0.7661 - loss: 1.0271 - val_f1_score: 0.3884 - val_loss: 2.8061\n",
      "Epoch 9/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 286ms/step - f1_score: 0.7858 - loss: 1.0311 - val_f1_score: 0.4351 - val_loss: 3.3131\n",
      "Epoch 10/20\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 288ms/step - f1_score: 0.7844 - loss: 1.0242 - val_f1_score: 0.3715 - val_loss: 2.5499\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - f1_score: 0.4565 - loss: 1.9998\n",
      "Test accuracy: [0.60759485 0.02739726 0.6303501  0.5585937 ]\n"
     ]
    }
   ],
   "source": [
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('brain_tumor_classifier.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
